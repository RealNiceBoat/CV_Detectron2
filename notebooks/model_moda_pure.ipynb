{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://detectron2.readthedocs.io/\n",
    "import detectron2\n",
    "import logging\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "logger = logging.getLogger('detectron2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "from pathlib import Path\n",
    "base_folder = Path('..')\n",
    "data_folder = base_folder/'data'/'modanet'\n",
    "train_imgs_folder = data_folder/'train'\n",
    "train_annotations = data_folder/'train.json'\n",
    "val_imgs_folder = data_folder/'train'\n",
    "val_annotations = data_folder/'val.json'\n",
    "test_imgs_folder = data_folder/'CV_final_images'\n",
    "test_annotations = data_folder/'CV_final_evaluation.json'\n",
    "\n",
    "save_model_folder = base_folder/'ckpts'\n",
    "load_model_folder = base_folder/'final_ckpts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#register datasets. now they can be used as if they were native. remember to run fix_annotations.py to convert TIL2020 to proper COCO format\n",
    "#to implement custom loaders, such as pickled, https://detectron2.readthedocs.io/modules/data.html?highlight=DatasetCatalog#detectron2.data.DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"moda_train\", {}, train_annotations, train_imgs_folder)\n",
    "register_coco_instances(\"moda_val\", {}, val_annotations, val_imgs_folder)\n",
    "register_coco_instances(\"til_test\", {}, base_folder/'data'/'til2020'/'CV_final_evaluation.json', base_folder/'data'/'til2020'/'CV_final_images')\n",
    "register_coco_instances(\"til_val\", {}, base_folder/'data'/'til2020'/'val.json', base_folder/'data'/'til2020'/'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32m[06/20 13:22:24 detectron2]: \u001b[0mLoaded Config:\nCUDNN_BENCHMARK: false\nDATALOADER:\n  ASPECT_RATIO_GROUPING: true\n  FILTER_EMPTY_ANNOTATIONS: true\n  NUM_WORKERS: 12\n  REPEAT_THRESHOLD: 0.05\n  SAMPLER_TRAIN: RepeatFactorTrainingSampler\nDATASETS:\n  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n  PROPOSAL_FILES_TEST: []\n  PROPOSAL_FILES_TRAIN: []\n  TEST:\n  - moda_val\n  TRAIN:\n  - moda_train\nGLOBAL:\n  HACK: 1.0\nINPUT:\n  CROP:\n    ENABLED: false\n    SIZE:\n    - 0.9\n    - 0.9\n    TYPE: relative_range\n  ENABLE_MINOR_AUGMENTS: false\n  FORMAT: BGR\n  MASK_FORMAT: polygon\n  MAX_SIZE_TEST: 1333\n  MAX_SIZE_TRAIN: 1333\n  MIN_SIZE_TEST: 560\n  MIN_SIZE_TRAIN:\n  - 400\n  - 432\n  - 464\n  - 496\n  - 528\n  - 560\n  MIN_SIZE_TRAIN_SAMPLING: choice\nMODEL:\n  ANCHOR_GENERATOR:\n    ANGLES:\n    - - -90\n      - 0\n      - 90\n    ASPECT_RATIOS:\n    - - 0.5\n      - 1.0\n      - 2.0\n    NAME: DefaultAnchorGenerator\n    OFFSET: 0.0\n    SIZES:\n    - - 32\n    - - 64\n    - - 128\n    - - 256\n    - - 512\n  BACKBONE:\n    FREEZE_AT: 2\n    NAME: build_resnet_fpn_backbone\n  DEVICE: cuda\n  FPN:\n    FUSE_TYPE: sum\n    IN_FEATURES:\n    - res2\n    - res3\n    - res4\n    - res5\n    NORM: ''\n    OUT_CHANNELS: 256\n  KEYPOINT_ON: false\n  LOAD_PROPOSALS: false\n  MASK_ON: false\n  META_ARCHITECTURE: GeneralizedRCNN\n  PANOPTIC_FPN:\n    COMBINE:\n      ENABLED: true\n      INSTANCES_CONFIDENCE_THRESH: 0.5\n      OVERLAP_THRESH: 0.5\n      STUFF_AREA_LIMIT: 4096\n    INSTANCE_LOSS_WEIGHT: 1.0\n  PIXEL_MEAN:\n  - 103.53\n  - 116.28\n  - 123.675\n  PIXEL_STD:\n  - 1.0\n  - 1.0\n  - 1.0\n  PROPOSAL_GENERATOR:\n    MIN_SIZE: 0\n    NAME: RPN\n  RESNETS:\n    DEFORM_MODULATED: false\n    DEFORM_NUM_GROUPS: 1\n    DEFORM_ON_PER_STAGE:\n    - false\n    - false\n    - false\n    - false\n    DEPTH: 101\n    NORM: FrozenBN\n    NUM_GROUPS: 1\n    OUT_FEATURES:\n    - res2\n    - res3\n    - res4\n    - res5\n    RES2_OUT_CHANNELS: 256\n    RES5_DILATION: 1\n    STEM_OUT_CHANNELS: 64\n    STRIDE_IN_1X1: true\n    WIDTH_PER_GROUP: 64\n  RETINANET:\n    BBOX_REG_WEIGHTS: &id002\n    - 1.0\n    - 1.0\n    - 1.0\n    - 1.0\n    FOCAL_LOSS_ALPHA: 0.25\n    FOCAL_LOSS_GAMMA: 2.0\n    IN_FEATURES:\n    - p3\n    - p4\n    - p5\n    - p6\n    - p7\n    IOU_LABELS:\n    - 0\n    - -1\n    - 1\n    IOU_THRESHOLDS:\n    - 0.4\n    - 0.5\n    NMS_THRESH_TEST: 0.5\n    NUM_CLASSES: 80\n    NUM_CONVS: 4\n    PRIOR_PROB: 0.01\n    SCORE_THRESH_TEST: 0.05\n    SMOOTH_L1_LOSS_BETA: 0.1\n    TOPK_CANDIDATES_TEST: 1000\n  ROI_BOX_CASCADE_HEAD:\n    BBOX_REG_WEIGHTS:\n    - &id001\n      - 10.0\n      - 10.0\n      - 5.0\n      - 5.0\n    - - 20.0\n      - 20.0\n      - 10.0\n      - 10.0\n    - - 30.0\n      - 30.0\n      - 15.0\n      - 15.0\n    IOUS:\n    - 0.5\n    - 0.6\n    - 0.7\n  ROI_BOX_HEAD:\n    BBOX_REG_WEIGHTS: *id001\n    CLS_AGNOSTIC_BBOX_REG: false\n    CONV_DIM: 256\n    FC_DIM: 1024\n    NAME: FastRCNNConvFCHead\n    NORM: ''\n    NUM_CONV: 0\n    NUM_FC: 2\n    POOLER_RESOLUTION: 7\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n    SMOOTH_L1_BETA: 0.0\n    TRAIN_ON_PRED_BOXES: false\n  ROI_HEADS:\n    BATCH_SIZE_PER_IMAGE: 512\n    IN_FEATURES:\n    - p2\n    - p3\n    - p4\n    - p5\n    IOU_LABELS:\n    - 0\n    - 1\n    IOU_THRESHOLDS:\n    - 0.5\n    NAME: StandardROIHeads\n    NMS_THRESH_TEST: 0.5\n    NUM_CLASSES: 5\n    POSITIVE_FRACTION: 0.25\n    PROPOSAL_APPEND_GT: true\n    SCORE_THRESH_TEST: 0.05\n  ROI_KEYPOINT_HEAD:\n    CONV_DIMS:\n    - 512\n    - 512\n    - 512\n    - 512\n    - 512\n    - 512\n    - 512\n    - 512\n    LOSS_WEIGHT: 1.0\n    MIN_KEYPOINTS_PER_IMAGE: 1\n    NAME: KRCNNConvDeconvUpsampleHead\n    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true\n    NUM_KEYPOINTS: 17\n    POOLER_RESOLUTION: 14\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n  ROI_MASK_HEAD:\n    CLS_AGNOSTIC_MASK: false\n    CONV_DIM: 256\n    NAME: MaskRCNNConvUpsampleHead\n    NORM: ''\n    NUM_CONV: 4\n    POOLER_RESOLUTION: 14\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n  RPN:\n    BATCH_SIZE_PER_IMAGE: 256\n    BBOX_REG_WEIGHTS: *id002\n    BOUNDARY_THRESH: -1\n    HEAD_NAME: StandardRPNHead\n    IN_FEATURES:\n    - p2\n    - p3\n    - p4\n    - p5\n    - p6\n    IOU_LABELS:\n    - 0\n    - -1\n    - 1\n    IOU_THRESHOLDS:\n    - 0.3\n    - 0.7\n    LOSS_WEIGHT: 1.0\n    NMS_THRESH: 0.7\n    POSITIVE_FRACTION: 0.5\n    POST_NMS_TOPK_TEST: 1000\n    POST_NMS_TOPK_TRAIN: 1000\n    PRE_NMS_TOPK_TEST: 1000\n    PRE_NMS_TOPK_TRAIN: 2000\n    SMOOTH_L1_BETA: 0.0\n  SEM_SEG_HEAD:\n    COMMON_STRIDE: 4\n    CONVS_DIM: 128\n    IGNORE_VALUE: 255\n    IN_FEATURES:\n    - p2\n    - p3\n    - p4\n    - p5\n    LOSS_WEIGHT: 1.0\n    NAME: SemSegFPNHead\n    NORM: GN\n    NUM_CLASSES: 54\n  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-101.pkl\nOUTPUT_DIR: ../ckpts\nPRINT_EVERY: 200\nSAVE_EVERY: 2000\nSEED: -1\nSOLVER:\n  BASE_LR: 0.000625\n  BIAS_LR_FACTOR: 1.0\n  CHECKPOINT_PERIOD: 5000\n  CLIP_GRADIENTS:\n    CLIP_TYPE: value\n    CLIP_VALUE: 1.0\n    ENABLED: false\n    NORM_TYPE: 2.0\n  GAMMA: 0.5\n  IMS_PER_BATCH: 5\n  LR_SCHEDULER_NAME: WarmupMultiStepLR\n  MAX_ITER: 1000000\n  MOMENTUM: 0.9\n  NESTEROV: false\n  STEPS:\n  - 100800000\n  WARMUP_FACTOR: 0.001\n  WARMUP_ITERS: 1000\n  WARMUP_METHOD: linear\n  WEIGHT_DECAY: 0.0001\n  WEIGHT_DECAY_BIAS: 0.0001\n  WEIGHT_DECAY_NORM: 0.0\nTEST:\n  AUG:\n    ENABLED: false\n    FLIP: true\n    MAX_SIZE: 4000\n    MIN_SIZES:\n    - 400\n    - 500\n    - 600\n    - 700\n    - 800\n    - 900\n    - 1000\n    - 1100\n    - 1200\n  DETECTIONS_PER_IMAGE: 100\n  EVAL_PERIOD: 0\n  EXPECTED_RESULTS: []\n  KEYPOINT_OKS_SIGMAS: []\n  PRECISE_BN:\n    ENABLED: false\n    NUM_ITER: 200\nVERSION: 2\nVIS_PERIOD: 0\n\n"
    }
   ],
   "source": [
    "#https://detectron2.readthedocs.io/modules/config.html\n",
    "#btw, i added some custom config options for my checkpointer and pipeline\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "#cfg.SEED = 42\n",
    "\n",
    "#All the images in this dataset are 400x600... hey but 4 times the TIL data\n",
    "cfg.DATASETS.TRAIN = (\"moda_train\",)\n",
    "cfg.DATASETS.TEST = (\"moda_val\",)\n",
    "cfg.OUTPUT_DIR = str(save_model_folder)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 12\n",
    "cfg.DATALOADER.SAMPLER_TRAIN = \"RepeatFactorTrainingSampler\" #deals with class imbalance\n",
    "cfg.DATALOADER.REPEAT_THRESHOLD = 0.05\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 5 #batch_size\n",
    "cfg.SOLVER.BASE_LR = 0.000625\n",
    "cfg.SOLVER.GAMMA = 0.5 #halves the learning rate at each milestone\n",
    "cfg.SOLVER.STEPS = (100800000,)#(20000,60000,100000,140000) # milestones in iterations\n",
    "#^I played with these but realised it had little effect: so keep BASE_LR at 0.000125*IMS_PER_BATCH\n",
    "\n",
    "#Pipeline augmentation settings (i implemented these)\n",
    "cfg.INPUT.CROP.ENABLED = False\n",
    "cfg.INPUT.ENABLE_MINOR_AUGMENTS = False\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (400,432,464,496,528,560) #mimmicking the original config but adapted for the 400x600 dimension\n",
    "cfg.INPUT.MIN_SIZE_TEST = 560\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5 #number of categories (remapped the dataset)\n",
    "cfg.PRINT_EVERY = 200\n",
    "cfg.SAVE_EVERY = 2000 #when using ValCheckpointer, it saves only if val loss is the minimum so far\n",
    "\n",
    "cfg.SOLVER.MAX_ITER = 1000000\n",
    "\n",
    "logger.info(f\"Loaded Config:\\n{cfg.dump()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n      )\n      (res3): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n      )\n      (res4): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (4): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (5): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (6): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (7): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (8): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (9): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (10): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (11): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (12): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (13): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (14): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (15): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (16): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (17): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (18): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (19): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (20): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (21): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (22): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n      )\n      (res5): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n      )\n    )\n  )\n  (proposal_generator): RPN(\n    (rpn_head): StandardRPNHead(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (anchor_generator): DefaultAnchorGenerator(\n      (cell_anchors): BufferList()\n    )\n  )\n  (roi_heads): StandardROIHeads(\n    (box_pooler): ROIPooler(\n      (level_poolers): ModuleList(\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n      )\n    )\n    (box_head): FastRCNNConvFCHead(\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n    (box_predictor): FastRCNNOutputLayers(\n      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n    )\n  )\n)\n"
    }
   ],
   "source": [
    "from detectron2.modeling import build_model\n",
    "from scripts.trainer import do_train,do_test\n",
    "model = build_model(cfg)\n",
    "logger.info(f\"Created Model:\\n{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32m[06/20 10:24:00 detectron2]: \u001b[0mResumed model: ft-til_resnet101_rcnn_moda_od\n\u001b[32m[06/20 10:24:00 detectron2]: \u001b[0mPipeline: [ResizeShortestEdge(short_edge_length=(400, 432, 464, 496, 528, 560), max_size=1333, sample_style='choice'), RandomFlip()]\n\u001b[32m[06/20 10:24:02 d2.data.datasets.coco]: \u001b[0mLoading ../data/modanet/train.json takes 1.59 seconds.\n\u001b[32m[06/20 10:24:02 d2.data.datasets.coco]: \u001b[0mLoaded 50661 images in COCO format from ../data/modanet/train.json\n\u001b[32m[06/20 10:24:02 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 50661 images left.\n\u001b[32m[06/20 10:24:04 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n|    tops    | 35250        |  trousers  | 29351        | outerwear  | 24460        |\n|  dresses   | 14101        |   skirts   | 13264        |            |              |\n|   total    | 116426       |            |              |            |              |\u001b[0m\n\u001b[32m[06/20 10:24:04 d2.data.common]: \u001b[0mSerializing 50661 elements to byte tensors and concatenating them all ...\n\u001b[32m[06/20 10:24:04 d2.data.common]: \u001b[0mSerialized dataset takes 37.97 MiB\n\u001b[32m[06/20 10:24:04 d2.data.build]: \u001b[0mUsing training sampler RepeatFactorTrainingSampler\n\u001b[32m[06/20 10:24:04 detectron2]: \u001b[0mTraining: Start Iter 69844, End Iter 1000000\n\u001b[32m[06/20 10:25:35 detectron2]: \u001b[0mPipeline: [ResizeShortestEdge(short_edge_length=(560, 560), max_size=1333, sample_style='choice')]\n\u001b[32m[06/20 10:25:35 d2.data.datasets.coco]: \u001b[0mLoaded 1567 images in COCO format from ../data/modanet/val.json\n\u001b[32m[06/20 10:25:35 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n|    tops    | 1040         |  trousers  | 897          | outerwear  | 748          |\n|  dresses   | 491          |   skirts   | 391          |            |              |\n|   total    | 3567         |            |              |            |              |\u001b[0m\n\u001b[32m[06/20 10:25:35 d2.data.common]: \u001b[0mSerializing 1567 elements to byte tensors and concatenating them all ...\n\u001b[32m[06/20 10:25:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.17 MiB\n\u001b[32m[06/20 10:25:35 detectron2]: \u001b[0mCalculating Validation Loss...\n100%|██████████| 1567/1567 [01:44<00:00, 15.00it/s]\n\n\u001b[32m[06/20 10:27:20 detectron2]: \u001b[0mVal Loss: 0.17779839038848877 @ Iteration 69999, Min Val Loss: 0.170448437333107, did not save model.\n\n\u001b[32m[06/20 10:27:20 d2.utils.events]: \u001b[0m iter: 70000  total_loss: 0.158  loss_cls: 0.072  loss_box_reg: 0.081  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  lr: 0.000625  max_mem: 4272M\n\u001b[32m[06/20 10:27:28 detectron2]: \u001b[0mERROR! Dumping current model...\n"
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml\")\n",
    "#cfg.MODEL.WEIGHTS = str(load_model_folder/\"ft-til_resnet101_rcnn_moda-65999-best_val.pth\")\n",
    "do_train(cfg,model,\"ft-til_resnet101_rcnn_moda_od\",resume=True)\n",
    "#if this doesnt work correctly, check what model is set in the  file in /ckpts/last_checkpoint\n",
    "#I uploaded the model file to the google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32m[06/20 13:22:28 d2.data.datasets.coco]: \u001b[0mLoaded 1972 images in COCO format from ../data/til2020/CV_final_evaluation.json\n\u001b[32m[06/20 13:22:28 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n|    tops    | 0            |  trousers  | 0            | outerwear  | 0            |\n|  dresses   | 0            |   skirts   | 0            |            |              |\n|   total    | 0            |            |              |            |              |\u001b[0m\n\u001b[32m[06/20 13:22:28 d2.data.common]: \u001b[0mSerializing 1972 elements to byte tensors and concatenating them all ...\n\u001b[32m[06/20 13:22:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.23 MiB\n\u001b[32m[06/20 13:22:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 1972 images\n\u001b[32m[06/20 13:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/1972. 0.0606 s / img. ETA=0:01:59\n\u001b[32m[06/20 13:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 96/1972. 0.0562 s / img. ETA=0:01:50\n\u001b[32m[06/20 13:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 188/1972. 0.0549 s / img. ETA=0:01:41\n\u001b[32m[06/20 13:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 277/1972. 0.0550 s / img. ETA=0:01:35\n\u001b[32m[06/20 13:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 359/1972. 0.0547 s / img. ETA=0:01:33\n\u001b[32m[06/20 13:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 442/1972. 0.0551 s / img. ETA=0:01:29\n\u001b[32m[06/20 13:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 526/1972. 0.0553 s / img. ETA=0:01:24\n\u001b[32m[06/20 13:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 612/1972. 0.0556 s / img. ETA=0:01:19\n\u001b[32m[06/20 13:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 698/1972. 0.0559 s / img. ETA=0:01:14\n\u001b[32m[06/20 13:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 774/1972. 0.0558 s / img. ETA=0:01:11\n\u001b[32m[06/20 13:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 858/1972. 0.0558 s / img. ETA=0:01:06\n\u001b[32m[06/20 13:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 945/1972. 0.0557 s / img. ETA=0:01:00\n\u001b[32m[06/20 13:23:30 d2.evaluation.evaluator]: \u001b[0mInference done 1024/1972. 0.0558 s / img. ETA=0:00:56\n\u001b[32m[06/20 13:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 1112/1972. 0.0556 s / img. ETA=0:00:51\n\u001b[32m[06/20 13:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 1192/1972. 0.0555 s / img. ETA=0:00:46\n\u001b[32m[06/20 13:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 1279/1972. 0.0554 s / img. ETA=0:00:41\n\u001b[32m[06/20 13:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 1368/1972. 0.0553 s / img. ETA=0:00:35\n\u001b[32m[06/20 13:23:55 d2.evaluation.evaluator]: \u001b[0mInference done 1455/1972. 0.0552 s / img. ETA=0:00:30\n\u001b[32m[06/20 13:24:00 d2.evaluation.evaluator]: \u001b[0mInference done 1540/1972. 0.0552 s / img. ETA=0:00:25\n\u001b[32m[06/20 13:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 1605/1972. 0.0552 s / img. ETA=0:00:22\n\u001b[32m[06/20 13:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 1687/1972. 0.0552 s / img. ETA=0:00:17\n\u001b[32m[06/20 13:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 1776/1972. 0.0551 s / img. ETA=0:00:11\n\u001b[32m[06/20 13:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 1867/1972. 0.0551 s / img. ETA=0:00:06\n\u001b[32m[06/20 13:24:26 d2.evaluation.evaluator]: \u001b[0mInference done 1951/1972. 0.0552 s / img. ETA=0:00:01\n\u001b[32m[06/20 13:24:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:57.503373 (0.059737 s / img per device, on 1 devices)\n\u001b[32m[06/20 13:24:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:48 (0.055171 s / img per device, on 1 devices)\n\u001b[32m[06/20 13:24:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[06/20 13:24:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../ckpts/coco_instances_results.json\n\u001b[32m[06/20 13:24:27 d2.evaluation.coco_evaluation]: \u001b[0mAnnotations are not available for evaluation.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<detectron2.evaluation.coco_evaluation.COCOEvaluator at 0x7f5465524f40>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#if do_train() hasnt been called (it loads the model) and you want to load the model\n",
    "if True:\n",
    "    from detectron2.checkpoint import DetectionCheckpointer\n",
    "    cfg.MODEL.WEIGHTS = str(load_model_folder/\"ft-til_resnet101_rcnn_moda_od-63999-best_val.pth\")\n",
    "    #cfg.MODEL.WEIGHTS = str(load_model_folder/\"ft-til_resnet101_rcnn_moda-103999-best_val.pth\")\n",
    "    DetectionCheckpointer(model, cfg.OUTPUT_DIR).resume_or_load(cfg.MODEL.WEIGHTS, resume=False)\n",
    "\n",
    "do_test(cfg,model,dataset_name='til_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = do_test(cfg,model,dataset_name='til_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = str(load_model_folder/\"ft-til_resnet101_rcnn_moda-65999-best_val.pth\")\n",
    "with open(load_model_folder/f'ft-til_resnet101_rcnn_moda','w') as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "im = cv2.imread(train_imgs_folder/\"69.jpg\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TEST[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "im_out = Image.fromarray(v.get_image()[:, :, ::-1]) #channels are reversed\n",
    "#display(im_out)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitdetectronconda1819ced9d1b04054b76de77970507a6d",
   "display_name": "Python 3.8.3 64-bit ('detectron': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}