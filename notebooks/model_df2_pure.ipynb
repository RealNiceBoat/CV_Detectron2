{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://detectron2.readthedocs.io/\n",
    "import detectron2\n",
    "import logging\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "logger = logging.getLogger('detectron2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "from pathlib import Path\n",
    "base_folder = Path('..')\n",
    "data_folder = base_folder/'data'/'df2'\n",
    "train_imgs_folder = data_folder/'train'\n",
    "train_annotations = data_folder/'train.json'\n",
    "\n",
    "save_model_folder = base_folder/'ckpts'\n",
    "load_model_folder = base_folder/'final_ckpts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#register datasets. now they can be used as if they were native. remember to run fix_annotations.py to convert TIL2020 to proper COCO format\n",
    "#to implement custom loaders, such as pickled, https://detectron2.readthedocs.io/modules/data.html?highlight=DatasetCatalog#detectron2.data.DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"df2_train\", {}, train_annotations, train_imgs_folder)\n",
    "register_coco_instances(\"til_test\", {}, base_folder/'data'/'til2020'/'CV_final_evaluation.json', base_folder/'data'/'til2020'/'CV_final_images')\n",
    "register_coco_instances(\"til_val\", {}, base_folder/'data'/'til2020'/'val.json', base_folder/'data'/'til2020'/'val')\n",
    "register_coco_instances(\"moda_val\", {}, base_folder/'data'/'modanet'/'val.json', base_folder/'data'/'modanet'/'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32m[06/20 13:26:57 detectron2]: \u001b[0mLoaded Config:\nCUDNN_BENCHMARK: false\nDATALOADER:\n  ASPECT_RATIO_GROUPING: true\n  FILTER_EMPTY_ANNOTATIONS: true\n  NUM_WORKERS: 16\n  REPEAT_THRESHOLD: 0.05\n  SAMPLER_TRAIN: RepeatFactorTrainingSampler\nDATASETS:\n  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n  PROPOSAL_FILES_TEST: []\n  PROPOSAL_FILES_TRAIN: []\n  TEST:\n  - til_val\n  TRAIN:\n  - df2_train\nGLOBAL:\n  HACK: 1.0\nINPUT:\n  CROP:\n    ENABLED: false\n    SIZE:\n    - 0.9\n    - 0.9\n    TYPE: relative_range\n  ENABLE_MINOR_AUGMENTS: false\n  FORMAT: BGR\n  MASK_FORMAT: polygon\n  MAX_SIZE_TEST: 1333\n  MAX_SIZE_TRAIN: 1333\n  MIN_SIZE_TEST: 560\n  MIN_SIZE_TRAIN:\n  - 400\n  - 432\n  - 464\n  - 496\n  - 528\n  - 560\n  MIN_SIZE_TRAIN_SAMPLING: choice\nMODEL:\n  ANCHOR_GENERATOR:\n    ANGLES:\n    - - -90\n      - 0\n      - 90\n    ASPECT_RATIOS:\n    - - 0.5\n      - 1.0\n      - 2.0\n    NAME: DefaultAnchorGenerator\n    OFFSET: 0.0\n    SIZES:\n    - - 32\n    - - 64\n    - - 128\n    - - 256\n    - - 512\n  BACKBONE:\n    FREEZE_AT: 2\n    NAME: build_resnet_fpn_backbone\n  DEVICE: cuda\n  FPN:\n    FUSE_TYPE: sum\n    IN_FEATURES:\n    - res2\n    - res3\n    - res4\n    - res5\n    NORM: ''\n    OUT_CHANNELS: 256\n  KEYPOINT_ON: false\n  LOAD_PROPOSALS: false\n  MASK_ON: false\n  META_ARCHITECTURE: GeneralizedRCNN\n  PANOPTIC_FPN:\n    COMBINE:\n      ENABLED: true\n      INSTANCES_CONFIDENCE_THRESH: 0.5\n      OVERLAP_THRESH: 0.5\n      STUFF_AREA_LIMIT: 4096\n    INSTANCE_LOSS_WEIGHT: 1.0\n  PIXEL_MEAN:\n  - 103.53\n  - 116.28\n  - 123.675\n  PIXEL_STD:\n  - 1.0\n  - 1.0\n  - 1.0\n  PROPOSAL_GENERATOR:\n    MIN_SIZE: 0\n    NAME: RPN\n  RESNETS:\n    DEFORM_MODULATED: false\n    DEFORM_NUM_GROUPS: 1\n    DEFORM_ON_PER_STAGE:\n    - false\n    - false\n    - false\n    - false\n    DEPTH: 101\n    NORM: FrozenBN\n    NUM_GROUPS: 1\n    OUT_FEATURES:\n    - res2\n    - res3\n    - res4\n    - res5\n    RES2_OUT_CHANNELS: 256\n    RES5_DILATION: 1\n    STEM_OUT_CHANNELS: 64\n    STRIDE_IN_1X1: true\n    WIDTH_PER_GROUP: 64\n  RETINANET:\n    BBOX_REG_WEIGHTS: &id002\n    - 1.0\n    - 1.0\n    - 1.0\n    - 1.0\n    FOCAL_LOSS_ALPHA: 0.25\n    FOCAL_LOSS_GAMMA: 2.0\n    IN_FEATURES:\n    - p3\n    - p4\n    - p5\n    - p6\n    - p7\n    IOU_LABELS:\n    - 0\n    - -1\n    - 1\n    IOU_THRESHOLDS:\n    - 0.4\n    - 0.5\n    NMS_THRESH_TEST: 0.5\n    NUM_CLASSES: 80\n    NUM_CONVS: 4\n    PRIOR_PROB: 0.01\n    SCORE_THRESH_TEST: 0.05\n    SMOOTH_L1_LOSS_BETA: 0.1\n    TOPK_CANDIDATES_TEST: 1000\n  ROI_BOX_CASCADE_HEAD:\n    BBOX_REG_WEIGHTS:\n    - &id001\n      - 10.0\n      - 10.0\n      - 5.0\n      - 5.0\n    - - 20.0\n      - 20.0\n      - 10.0\n      - 10.0\n    - - 30.0\n      - 30.0\n      - 15.0\n      - 15.0\n    IOUS:\n    - 0.5\n    - 0.6\n    - 0.7\n  ROI_BOX_HEAD:\n    BBOX_REG_WEIGHTS: *id001\n    CLS_AGNOSTIC_BBOX_REG: false\n    CONV_DIM: 256\n    FC_DIM: 1024\n    NAME: FastRCNNConvFCHead\n    NORM: ''\n    NUM_CONV: 0\n    NUM_FC: 2\n    POOLER_RESOLUTION: 7\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n    SMOOTH_L1_BETA: 0.0\n    TRAIN_ON_PRED_BOXES: false\n  ROI_HEADS:\n    BATCH_SIZE_PER_IMAGE: 512\n    IN_FEATURES:\n    - p2\n    - p3\n    - p4\n    - p5\n    IOU_LABELS:\n    - 0\n    - 1\n    IOU_THRESHOLDS:\n    - 0.5\n    NAME: StandardROIHeads\n    NMS_THRESH_TEST: 0.5\n    NUM_CLASSES: 5\n    POSITIVE_FRACTION: 0.25\n    PROPOSAL_APPEND_GT: true\n    SCORE_THRESH_TEST: 0.05\n  ROI_KEYPOINT_HEAD:\n    CONV_DIMS:\n    - 512\n    - 512\n    - 512\n    - 512\n    - 512\n    - 512\n    - 512\n    - 512\n    LOSS_WEIGHT: 1.0\n    MIN_KEYPOINTS_PER_IMAGE: 1\n    NAME: KRCNNConvDeconvUpsampleHead\n    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true\n    NUM_KEYPOINTS: 17\n    POOLER_RESOLUTION: 14\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n  ROI_MASK_HEAD:\n    CLS_AGNOSTIC_MASK: false\n    CONV_DIM: 256\n    NAME: MaskRCNNConvUpsampleHead\n    NORM: ''\n    NUM_CONV: 4\n    POOLER_RESOLUTION: 14\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n  RPN:\n    BATCH_SIZE_PER_IMAGE: 256\n    BBOX_REG_WEIGHTS: *id002\n    BOUNDARY_THRESH: -1\n    HEAD_NAME: StandardRPNHead\n    IN_FEATURES:\n    - p2\n    - p3\n    - p4\n    - p5\n    - p6\n    IOU_LABELS:\n    - 0\n    - -1\n    - 1\n    IOU_THRESHOLDS:\n    - 0.3\n    - 0.7\n    LOSS_WEIGHT: 1.0\n    NMS_THRESH: 0.7\n    POSITIVE_FRACTION: 0.5\n    POST_NMS_TOPK_TEST: 1000\n    POST_NMS_TOPK_TRAIN: 1000\n    PRE_NMS_TOPK_TEST: 1000\n    PRE_NMS_TOPK_TRAIN: 2000\n    SMOOTH_L1_BETA: 0.0\n  SEM_SEG_HEAD:\n    COMMON_STRIDE: 4\n    CONVS_DIM: 128\n    IGNORE_VALUE: 255\n    IN_FEATURES:\n    - p2\n    - p3\n    - p4\n    - p5\n    LOSS_WEIGHT: 1.0\n    NAME: SemSegFPNHead\n    NORM: GN\n    NUM_CLASSES: 54\n  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-101.pkl\nOUTPUT_DIR: ../ckpts\nPRINT_EVERY: 200\nSAVE_EVERY: 2000\nSEED: -1\nSOLVER:\n  BASE_LR: 0.0005\n  BIAS_LR_FACTOR: 1.0\n  CHECKPOINT_PERIOD: 5000\n  CLIP_GRADIENTS:\n    CLIP_TYPE: value\n    CLIP_VALUE: 1.0\n    ENABLED: false\n    NORM_TYPE: 2.0\n  GAMMA: 0.5\n  IMS_PER_BATCH: 4\n  LR_SCHEDULER_NAME: WarmupMultiStepLR\n  MAX_ITER: 1000000\n  MOMENTUM: 0.9\n  NESTEROV: false\n  STEPS:\n  - 100800000\n  WARMUP_FACTOR: 0.001\n  WARMUP_ITERS: 1000\n  WARMUP_METHOD: linear\n  WEIGHT_DECAY: 0.0001\n  WEIGHT_DECAY_BIAS: 0.0001\n  WEIGHT_DECAY_NORM: 0.0\nTEST:\n  AUG:\n    ENABLED: false\n    FLIP: true\n    MAX_SIZE: 4000\n    MIN_SIZES:\n    - 400\n    - 500\n    - 600\n    - 700\n    - 800\n    - 900\n    - 1000\n    - 1100\n    - 1200\n  DETECTIONS_PER_IMAGE: 100\n  EVAL_PERIOD: 0\n  EXPECTED_RESULTS: []\n  KEYPOINT_OKS_SIGMAS: []\n  PRECISE_BN:\n    ENABLED: false\n    NUM_ITER: 200\nVERSION: 2\nVIS_PERIOD: 0\n\n"
    }
   ],
   "source": [
    "#https://detectron2.readthedocs.io/modules/config.html\n",
    "#btw, i added some custom config options for my checkpointer and pipeline\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "#cfg.SEED = 42\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"df2_train\",)\n",
    "cfg.DATASETS.TEST = (\"til_val\",)\n",
    "cfg.OUTPUT_DIR = str(save_model_folder)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 16\n",
    "cfg.DATALOADER.SAMPLER_TRAIN = \"RepeatFactorTrainingSampler\" #deals with class imbalance\n",
    "cfg.DATALOADER.REPEAT_THRESHOLD = 0.05\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4 #batch_size\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.5 #halves the learning rate at each milestone\n",
    "cfg.SOLVER.STEPS = (100800000,)#(20000,60000,100000,140000) # milestones in iterations\n",
    "#^I played with these but realised it had little effect: so keep BASE_LR at 0.000125*IMS_PER_BATCH\n",
    "\n",
    "#Pipeline augmentation settings (i implemented these)\n",
    "cfg.INPUT.CROP.ENABLED = False\n",
    "cfg.INPUT.ENABLE_MINOR_AUGMENTS = False\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (400,432,464,496,528,560) #mimmicking the original config but adapted for the 400x600 dimension\n",
    "cfg.INPUT.MIN_SIZE_TEST = 560\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5 #number of categories (remapped the dataset)\n",
    "cfg.PRINT_EVERY = 200\n",
    "cfg.SAVE_EVERY = 2000 #when using ValCheckpointer, it saves only if val loss is the minimum so far\n",
    "\n",
    "cfg.SOLVER.MAX_ITER = 1000000\n",
    "\n",
    "logger.info(f\"Loaded Config:\\n{cfg.dump()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n      )\n      (res3): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n      )\n      (res4): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (4): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (5): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (6): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (7): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (8): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (9): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (10): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (11): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (12): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (13): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (14): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (15): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (16): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (17): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (18): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (19): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (20): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (21): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (22): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n      )\n      (res5): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n      )\n    )\n  )\n  (proposal_generator): RPN(\n    (rpn_head): StandardRPNHead(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (anchor_generator): DefaultAnchorGenerator(\n      (cell_anchors): BufferList()\n    )\n  )\n  (roi_heads): StandardROIHeads(\n    (box_pooler): ROIPooler(\n      (level_poolers): ModuleList(\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n      )\n    )\n    (box_head): FastRCNNConvFCHead(\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n    (box_predictor): FastRCNNOutputLayers(\n      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n    )\n  )\n)\n"
    }
   ],
   "source": [
    "from detectron2.modeling import build_model\n",
    "from scripts.trainer import do_train,do_test\n",
    "model = build_model(cfg)\n",
    "logger.info(f\"Created Model:\\n{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32m[06/19 15:06:15 detectron2]: \u001b[0mResumed model: ft-til_resnet101_rcnn_df2\n\u001b[32m[06/19 15:06:15 detectron2]: \u001b[0mPipeline: [ResizeShortestEdge(short_edge_length=(400, 432, 464, 496, 528, 560), max_size=1333, sample_style='choice'), RandomFlip()]\n\u001b[32m[06/19 15:06:20 d2.data.datasets.coco]: \u001b[0mLoading ../data/df2/train.json takes 4.88 seconds.\n\u001b[32m[06/19 15:06:20 d2.data.datasets.coco]: \u001b[0mLoaded 191961 images in COCO format from ../data/df2/train.json\n\u001b[32m[06/19 15:06:22 d2.data.build]: \u001b[0mRemoved 522 images with no usable annotations. 191439 images left.\n\u001b[32m[06/19 15:06:26 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n|    tops    | 107709       |  trousers  | 92003        | outerwear  | 30095        |\n|  dresses   | 49559        |   skirts   | 30835        |            |              |\n|   total    | 310201       |            |              |            |              |\u001b[0m\n\u001b[32m[06/19 15:06:26 d2.data.common]: \u001b[0mSerializing 191439 elements to byte tensors and concatenating them all ...\n\u001b[32m[06/19 15:06:27 d2.data.common]: \u001b[0mSerialized dataset takes 148.63 MiB\n\u001b[32m[06/19 15:06:27 d2.data.build]: \u001b[0mUsing training sampler RepeatFactorTrainingSampler\n\u001b[32m[06/19 15:06:28 detectron2]: \u001b[0mTraining: Start Iter 97813, End Iter 1000000\n\u001b[32m[06/19 15:07:57 detectron2]: \u001b[0mPipeline: [ResizeShortestEdge(short_edge_length=(560, 560), max_size=1333, sample_style='choice')]\n\u001b[32m[06/19 15:07:57 d2.data.datasets.coco]: \u001b[0mLoaded 1474 images in COCO format from ../data/til2020/val.json\n\u001b[32m[06/19 15:07:57 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n|    tops    | 317          |  trousers  | 313          | outerwear  | 316          |\n|  dresses   | 1338         |   skirts   | 174          |            |              |\n|   total    | 2458         |            |              |            |              |\u001b[0m\n\u001b[32m[06/19 15:07:57 d2.data.common]: \u001b[0mSerializing 1474 elements to byte tensors and concatenating them all ...\n\u001b[32m[06/19 15:07:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.37 MiB\n\u001b[32m[06/19 15:07:57 detectron2]: \u001b[0mCalculating Validation Loss...\n100%|██████████| 1474/1474 [01:35<00:00, 15.42it/s]\n\n\u001b[32m[06/19 15:09:32 detectron2]: \u001b[0mVal Loss: 0.2515938878059387 @ Iteration 97999, Min Val Loss: 999, saving model.\n\n\u001b[32m[06/19 15:09:33 d2.utils.events]: \u001b[0m iter: 98000  total_loss: 0.126  loss_cls: 0.054  loss_box_reg: 0.066  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000500  max_mem: 4818M\n\u001b[32m[06/19 15:11:06 d2.utils.events]: \u001b[0m eta: 4 days, 20:57:29  iter: 98200  total_loss: 0.119  loss_cls: 0.045  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000500  max_mem: 4818M\n\u001b[32m[06/19 15:11:50 detectron2]: \u001b[0mERROR! Dumping current model...\n"
    }
   ],
   "source": [
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml\")\n",
    "#cfg.MODEL.WEIGHTS = str(load_model_folder/\"ft-til_resnet101_rcnn_moda-65999-best_val.pth\")\n",
    "do_train(cfg,model,\"ft-til_resnet101_rcnn_df2\",resume=True,reset_val=True)\n",
    "#if this doesnt work correctly, check what model is set in the  file in /ckpts/last_checkpoint\n",
    "#I uploaded the model file to the google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32m[06/20 13:27:06 d2.data.datasets.coco]: \u001b[0mLoaded 1972 images in COCO format from ../data/til2020/CV_final_evaluation.json\n\u001b[32m[06/20 13:27:06 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n|    tops    | 0            |  trousers  | 0            | outerwear  | 0            |\n|  dresses   | 0            |   skirts   | 0            |            |              |\n|   total    | 0            |            |              |            |              |\u001b[0m\n\u001b[32m[06/20 13:27:06 d2.data.common]: \u001b[0mSerializing 1972 elements to byte tensors and concatenating them all ...\n\u001b[32m[06/20 13:27:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.23 MiB\n\u001b[32m[06/20 13:27:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 1972 images\n\u001b[32m[06/20 13:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/1972. 0.0591 s / img. ETA=0:01:56\n\u001b[32m[06/20 13:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 97/1972. 0.0563 s / img. ETA=0:01:49\n\u001b[32m[06/20 13:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 186/1972. 0.0560 s / img. ETA=0:01:42\n\u001b[32m[06/20 13:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 275/1972. 0.0560 s / img. ETA=0:01:37\n\u001b[32m[06/20 13:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 364/1972. 0.0556 s / img. ETA=0:01:31\n\u001b[32m[06/20 13:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 451/1972. 0.0559 s / img. ETA=0:01:26\n\u001b[32m[06/20 13:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 540/1972. 0.0559 s / img. ETA=0:01:21\n\u001b[32m[06/20 13:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 629/1972. 0.0559 s / img. ETA=0:01:16\n\u001b[32m[06/20 13:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 713/1972. 0.0562 s / img. ETA=0:01:12\n\u001b[32m[06/20 13:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 794/1972. 0.0563 s / img. ETA=0:01:08\n\u001b[32m[06/20 13:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 880/1972. 0.0565 s / img. ETA=0:01:03\n\u001b[32m[06/20 13:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 966/1972. 0.0566 s / img. ETA=0:00:58\n\u001b[32m[06/20 13:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 1051/1972. 0.0567 s / img. ETA=0:00:53\n\u001b[32m[06/20 13:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 1139/1972. 0.0567 s / img. ETA=0:00:48\n\u001b[32m[06/20 13:28:18 d2.evaluation.evaluator]: \u001b[0mInference done 1226/1972. 0.0566 s / img. ETA=0:00:43\n\u001b[32m[06/20 13:28:23 d2.evaluation.evaluator]: \u001b[0mInference done 1311/1972. 0.0566 s / img. ETA=0:00:38\n\u001b[32m[06/20 13:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 1400/1972. 0.0565 s / img. ETA=0:00:33\n\u001b[32m[06/20 13:28:33 d2.evaluation.evaluator]: \u001b[0mInference done 1493/1972. 0.0563 s / img. ETA=0:00:27\n\u001b[32m[06/20 13:28:38 d2.evaluation.evaluator]: \u001b[0mInference done 1568/1972. 0.0561 s / img. ETA=0:00:23\n\u001b[32m[06/20 13:28:43 d2.evaluation.evaluator]: \u001b[0mInference done 1663/1972. 0.0559 s / img. ETA=0:00:17\n\u001b[32m[06/20 13:28:48 d2.evaluation.evaluator]: \u001b[0mInference done 1759/1972. 0.0556 s / img. ETA=0:00:12\n\u001b[32m[06/20 13:28:53 d2.evaluation.evaluator]: \u001b[0mInference done 1850/1972. 0.0554 s / img. ETA=0:00:07\n\u001b[32m[06/20 13:28:58 d2.evaluation.evaluator]: \u001b[0mInference done 1943/1972. 0.0552 s / img. ETA=0:00:01\n\u001b[32m[06/20 13:29:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:52.503369 (0.057195 s / img per device, on 1 devices)\n\u001b[32m[06/20 13:29:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:48 (0.055177 s / img per device, on 1 devices)\n\u001b[32m[06/20 13:29:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[06/20 13:29:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../ckpts/coco_instances_results.json\n\u001b[32m[06/20 13:29:00 d2.evaluation.coco_evaluation]: \u001b[0mAnnotations are not available for evaluation.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<detectron2.evaluation.coco_evaluation.COCOEvaluator at 0x7fafe8813490>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#if do_train() hasnt been called (it loads the model) and you want to load the model\n",
    "if True:\n",
    "    from detectron2.checkpoint import DetectionCheckpointer\n",
    "    cfg.MODEL.WEIGHTS = str(load_model_folder/\"ft-til_resnet101_rcnn_df2-91999-best_val.pth\")\n",
    "    DetectionCheckpointer(model, cfg.OUTPUT_DIR).resume_or_load(cfg.MODEL.WEIGHTS, resume=False)\n",
    "\n",
    "do_test(cfg,model,dataset_name='til_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = do_test(cfg,model,dataset_name='til_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = str(load_model_folder/\"ft-til_resnet101_rcnn_moda-65999-best_val.pth\")\n",
    "with open(load_model_folder/f'ft-til_resnet101_rcnn_moda','w') as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "im = cv2.imread(train_imgs_folder/\"69.jpg\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TEST[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "im_out = Image.fromarray(v.get_image()[:, :, ::-1]) #channels are reversed\n",
    "#display(im_out)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitdetectronconda1819ced9d1b04054b76de77970507a6d",
   "display_name": "Python 3.8.3 64-bit ('detectron': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}